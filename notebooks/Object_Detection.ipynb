{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5oCq8HgrCvv"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdcNJd7UsDUC"
      },
      "outputs": [],
      "source": [
        "!pip install -U albumentations\n",
        "!cd /content/drive/MyDrive/Dial/Sellos-QA/obj_detection/src\n",
        "%cd /content/drive/MyDrive/Dial/Sellos-QA/obj_detection/src"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"engine.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6yWGjA2dPRY",
        "outputId": "c997218d-1b61-4157-c56a-dd84fdceec31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 801\n",
            "Number of validation samples: 199\n",
            "\n",
            "\n",
            "EPOCH 1 of 500\n",
            "Training\n",
            "  0% 0/201 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Loss: 0.2273: 100% 201/201 [06:55<00:00,  2.07s/it]\n",
            "Validating\n",
            "Loss: 0.3362: 100% 50/50 [00:49<00:00,  1.01it/s]\n",
            "Epoch #0 train loss: 0.443\n",
            "Epoch #0 validation loss: 0.323\n",
            "Took 7.742 minutes for epoch 0\n",
            "\n",
            "EPOCH 2 of 500\n",
            "Training\n",
            "Loss: 0.3252: 100% 201/201 [06:55<00:00,  2.07s/it]\n",
            "Validating\n",
            "Loss: 0.2368: 100% 50/50 [00:49<00:00,  1.01it/s]\n",
            "Epoch #1 train loss: 0.288\n",
            "Epoch #1 validation loss: 0.262\n",
            "Took 7.744 minutes for epoch 1\n",
            "SAVING MODEL COMPLETE...\n",
            "\n",
            "SAVING PLOTS COMPLETE...\n",
            "\n",
            "EPOCH 3 of 500\n",
            "Training\n",
            "Loss: 0.1617: 100% 201/201 [06:54<00:00,  2.06s/it]\n",
            "Validating\n",
            "Loss: 0.1967: 100% 50/50 [00:49<00:00,  1.01it/s]\n",
            "Epoch #2 train loss: 0.244\n",
            "Epoch #2 validation loss: 0.247\n",
            "Took 7.736 minutes for epoch 2\n",
            "\n",
            "EPOCH 4 of 500\n",
            "Training\n",
            "Loss: 0.1796: 100% 201/201 [06:54<00:00,  2.06s/it]\n",
            "Validating\n",
            "Loss: 0.1720: 100% 50/50 [00:49<00:00,  1.01it/s]\n",
            "Epoch #3 train loss: 0.221\n",
            "Epoch #3 validation loss: 0.217\n",
            "Took 7.736 minutes for epoch 3\n",
            "SAVING MODEL COMPLETE...\n",
            "\n",
            "SAVING PLOTS COMPLETE...\n",
            "\n",
            "EPOCH 5 of 500\n",
            "Training\n",
            "Loss: 0.2193: 100% 201/201 [06:54<00:00,  2.06s/it]\n",
            "Validating\n",
            "Loss: 0.1740: 100% 50/50 [00:49<00:00,  1.01it/s]\n",
            "Epoch #4 train loss: 0.207\n",
            "Epoch #4 validation loss: 0.194\n",
            "Took 7.736 minutes for epoch 4\n",
            "\n",
            "EPOCH 6 of 500\n",
            "Training\n",
            "Loss: 0.1921: 100% 201/201 [06:54<00:00,  2.06s/it]\n",
            "Validating\n",
            "Loss: 0.1642: 100% 50/50 [00:49<00:00,  1.01it/s]\n",
            "Epoch #5 train loss: 0.197\n",
            "Epoch #5 validation loss: 0.207\n",
            "Took 7.734 minutes for epoch 5\n",
            "SAVING MODEL COMPLETE...\n",
            "\n",
            "SAVING PLOTS COMPLETE...\n",
            "\n",
            "EPOCH 7 of 500\n",
            "Training\n",
            "Loss: 0.2657: 100% 201/201 [06:54<00:00,  2.06s/it]\n",
            "Validating\n",
            "Loss: 0.1661: 100% 50/50 [00:48<00:00,  1.02it/s]\n",
            "Epoch #6 train loss: 0.191\n",
            "Epoch #6 validation loss: 0.193\n",
            "Took 7.724 minutes for epoch 6\n",
            "\n",
            "EPOCH 8 of 500\n",
            "Training\n",
            "Loss: 0.1846: 100% 201/201 [06:54<00:00,  2.06s/it]\n",
            "Validating\n",
            "Loss: 0.1529: 100% 50/50 [00:49<00:00,  1.02it/s]\n",
            "Epoch #7 train loss: 0.185\n",
            "Epoch #7 validation loss: 0.194\n",
            "Took 7.719 minutes for epoch 7\n",
            "SAVING MODEL COMPLETE...\n",
            "\n",
            "SAVING PLOTS COMPLETE...\n",
            "\n",
            "EPOCH 9 of 500\n",
            "Training\n",
            "Loss: 0.2141: 100% 201/201 [06:53<00:00,  2.06s/it]\n",
            "Validating\n",
            "Loss: 0.1498: 100% 50/50 [00:49<00:00,  1.01it/s]\n",
            "Epoch #8 train loss: 0.185\n",
            "Epoch #8 validation loss: 0.181\n",
            "Took 7.722 minutes for epoch 8\n",
            "\n",
            "EPOCH 10 of 500\n",
            "Training\n",
            "Loss: 0.1996: 100% 201/201 [06:54<00:00,  2.06s/it]\n",
            "Validating\n",
            "Loss: 0.1507: 100% 50/50 [00:49<00:00,  1.02it/s]\n",
            "Epoch #9 train loss: 0.179\n",
            "Epoch #9 validation loss: 0.181\n",
            "Took 7.721 minutes for epoch 9\n",
            "SAVING MODEL COMPLETE...\n",
            "\n",
            "SAVING PLOTS COMPLETE...\n",
            "\n",
            "EPOCH 11 of 500\n",
            "Training\n",
            "Loss: 0.3473: 100% 201/201 [06:53<00:00,  2.06s/it]\n",
            "Validating\n",
            "Loss: 0.1544: 100% 50/50 [00:49<00:00,  1.02it/s]\n",
            "Epoch #10 train loss: 0.175\n",
            "Epoch #10 validation loss: 0.181\n",
            "Took 7.717 minutes for epoch 10\n",
            "\n",
            "EPOCH 12 of 500\n",
            "Training\n",
            "Loss: 0.1135: 100% 201/201 [06:54<00:00,  2.06s/it]\n",
            "Validating\n",
            "Loss: 0.1520: 100% 50/50 [00:49<00:00,  1.02it/s]\n",
            "Epoch #11 train loss: 0.178\n",
            "Epoch #11 validation loss: 0.181\n",
            "Took 7.720 minutes for epoch 11\n",
            "SAVING MODEL COMPLETE...\n",
            "\n",
            "SAVING PLOTS COMPLETE...\n",
            "\n",
            "EPOCH 13 of 500\n",
            "Training\n",
            "Loss: 0.1900: 100% 201/201 [06:53<00:00,  2.06s/it]\n",
            "Validating\n",
            "Loss: 0.1459: 100% 50/50 [00:49<00:00,  1.02it/s]\n",
            "Epoch #12 train loss: 0.172\n",
            "Epoch #12 validation loss: 0.177\n",
            "Took 7.711 minutes for epoch 12\n",
            "\n",
            "EPOCH 14 of 500\n",
            "Training\n",
            "Loss: 0.1136: 100% 201/201 [06:53<00:00,  2.06s/it]\n",
            "Validating\n",
            "Loss: 0.1635: 100% 50/50 [00:49<00:00,  1.02it/s]\n",
            "Epoch #13 train loss: 0.168\n",
            "Epoch #13 validation loss: 0.179\n",
            "Took 7.710 minutes for epoch 13\n",
            "SAVING MODEL COMPLETE...\n",
            "\n",
            "SAVING PLOTS COMPLETE...\n",
            "\n",
            "EPOCH 15 of 500\n",
            "Training\n",
            "Loss: 0.2588: 100% 201/201 [06:53<00:00,  2.06s/it]\n",
            "Validating\n",
            "Loss: 0.1591: 100% 50/50 [00:49<00:00,  1.01it/s]\n",
            "Epoch #14 train loss: 0.169\n",
            "Epoch #14 validation loss: 0.182\n",
            "Took 7.722 minutes for epoch 14\n",
            "\n",
            "EPOCH 16 of 500\n",
            "Training\n",
            "Loss: 0.2072:  26% 53/201 [01:48<05:05,  2.06s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKiZq919r3qj"
      },
      "outputs": [],
      "source": [
        "from config import DEVICE, NUM_CLASSES, NUM_EPOCHS, OUT_DIR\n",
        "from config import VISUALIZE_TRANSFORMED_IMAGES\n",
        "from config import SAVE_PLOTS_EPOCH, SAVE_MODEL_EPOCH\n",
        "from model import create_model\n",
        "from utils import Averager\n",
        "from tqdm.auto import tqdm\n",
        "from datasets import train_loader, valid_loader\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# function for running training iterations\n",
        "def train(train_data_loader, model):\n",
        "    print('Training')\n",
        "    global train_itr\n",
        "    global train_loss_list\n",
        "    \n",
        "     # initialize tqdm progress bar\n",
        "    prog_bar = tqdm(train_data_loader, total=len(train_data_loader))\n",
        "    \n",
        "    for i, data in enumerate(prog_bar):\n",
        "        optimizer.zero_grad()\n",
        "        images, targets = data\n",
        "        \n",
        "        images = list(image.to(DEVICE) for image in images)\n",
        "        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        loss_value = losses.item()\n",
        "        train_loss_list.append(loss_value)\n",
        "\n",
        "        train_loss_hist.send(loss_value)\n",
        "\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_itr += 1\n",
        "    \n",
        "        # update the loss value beside the progress bar for each iteration\n",
        "        prog_bar.set_description(desc=f\"Loss: {loss_value:.4f}\")\n",
        "    return train_loss_list\n",
        "\n",
        "# function for running validation iterations\n",
        "def validate(valid_data_loader, model):\n",
        "    print('Validating')\n",
        "    global val_itr\n",
        "    global val_loss_list\n",
        "    \n",
        "    # initialize tqdm progress bar\n",
        "    prog_bar = tqdm(valid_data_loader, total=len(valid_data_loader))\n",
        "    \n",
        "    for i, data in enumerate(prog_bar):\n",
        "        images, targets = data\n",
        "        \n",
        "        images = list(image.to(DEVICE) for image in images)\n",
        "        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            loss_dict = model(images, targets)\n",
        "\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        loss_value = losses.item()\n",
        "        val_loss_list.append(loss_value)\n",
        "\n",
        "        val_loss_hist.send(loss_value)\n",
        "\n",
        "        val_itr += 1\n",
        "\n",
        "        # update the loss value beside the progress bar for each iteration\n",
        "        prog_bar.set_description(desc=f\"Loss: {loss_value:.4f}\")\n",
        "    return val_loss_list\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # initialize the model and move to the computation device\n",
        "    model = create_model(num_classes=NUM_CLASSES)\n",
        "    model = model.to(DEVICE)\n",
        "    # get the model parameters\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    # define the optimizer\n",
        "    optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "    # initialize the Averager class\n",
        "    train_loss_hist = Averager()\n",
        "    val_loss_hist = Averager()\n",
        "    train_itr = 1\n",
        "    val_itr = 1\n",
        "    # train and validation loss lists to store loss values of all...\n",
        "    # ... iterations till ena and plot graphs for all iterations\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "\n",
        "    # name to save the trained model with\n",
        "    MODEL_NAME = 'model'\n",
        "\n",
        "    # whether to show transformed images from data loader or not\n",
        "    if VISUALIZE_TRANSFORMED_IMAGES:\n",
        "        from utils import show_tranformed_image\n",
        "        show_tranformed_image(train_loader)\n",
        "\n",
        "    # start the training epochs\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        print(f\"\\nEPOCH {epoch+1} of {NUM_EPOCHS}\")\n",
        "\n",
        "        # reset the training and validation loss histories for the current epoch\n",
        "        train_loss_hist.reset()\n",
        "        val_loss_hist.reset()\n",
        "\n",
        "        # create two subplots, one for each, training and validation\n",
        "        figure_1, train_ax = plt.subplots()\n",
        "        figure_2, valid_ax = plt.subplots()\n",
        "\n",
        "        # start timer and carry out training and validation\n",
        "        start = time.time()\n",
        "        train_loss = train(train_loader, model)\n",
        "        val_loss = validate(valid_loader, model)\n",
        "        print(f\"Epoch #{epoch} train loss: {train_loss_hist.value:.3f}\")   \n",
        "        print(f\"Epoch #{epoch} validation loss: {val_loss_hist.value:.3f}\")   \n",
        "        end = time.time()\n",
        "        print(f\"Took {((end - start) / 60):.3f} minutes for epoch {epoch}\")\n",
        "\n",
        "        if (epoch+1) % SAVE_MODEL_EPOCH == 0: # save model after every n epochs\n",
        "            torch.save(model.state_dict(), f\"{OUT_DIR}/model{epoch+1}.pth\")\n",
        "            print('SAVING MODEL COMPLETE...\\n')\n",
        "        \n",
        "        if (epoch+1) % SAVE_PLOTS_EPOCH == 0: # save loss plots after n epochs\n",
        "            train_ax.plot(train_loss, color='blue')\n",
        "            train_ax.set_xlabel('iterations')\n",
        "            train_ax.set_ylabel('train loss')\n",
        "            valid_ax.plot(val_loss, color='red')\n",
        "            valid_ax.set_xlabel('iterations')\n",
        "            valid_ax.set_ylabel('validation loss')\n",
        "            figure_1.savefig(f\"{OUT_DIR}/train_loss_{epoch+1}.png\")\n",
        "            figure_2.savefig(f\"{OUT_DIR}/valid_loss_{epoch+1}.png\")\n",
        "            print('SAVING PLOTS COMPLETE...')\n",
        "        \n",
        "        if (epoch+1) == NUM_EPOCHS: # save loss plots and model once at the end\n",
        "            train_ax.plot(train_loss, color='blue')\n",
        "            train_ax.set_xlabel('iterations')\n",
        "            train_ax.set_ylabel('train loss')\n",
        "            valid_ax.plot(val_loss, color='red')\n",
        "            valid_ax.set_xlabel('iterations')\n",
        "            valid_ax.set_ylabel('validation loss')\n",
        "            figure_1.savefig(f\"{OUT_DIR}/train_loss_{epoch+1}.png\")\n",
        "            figure_2.savefig(f\"{OUT_DIR}/valid_loss_{epoch+1}.png\")\n",
        "\n",
        "            torch.save(model.state_dict(), f\"{OUT_DIR}/model{epoch+1}.pth\")\n",
        "        \n",
        "        plt.close('all')\n",
        "        # sleep for 5 seconds after each epoch\n",
        "        time.sleep(5)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Object_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}